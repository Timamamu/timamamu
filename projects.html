<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Fatima Mamu - Projects</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="description" content="Fatima Mamu - Projects" />
  <meta name="keywords" content="portfolio, product engineer, computer vision, unity, full-stack" />
  <meta name="author" content="lmpixels" />
  <link rel="shortcut icon" href="favicon.ico">

  <link rel="stylesheet" href="css/normalize.css" type="text/css">
  <link rel="stylesheet" href="css/bootstrap.min.css" type="text/css">
  <link rel="stylesheet" href="css/owl.carousel.css" type="text/css">
  <link rel="stylesheet" href="css/magnific-popup.css" type="text/css">
  <link rel="stylesheet" href="css/main.css" type="text/css">
  <link rel="stylesheet" href="css/style.css" type="text/css">

  <script src="js/modernizr.custom.js"></script>
</head>

<body class="page">
  <div class="lm-animated-bg"></div>

  <!-- Loading animation -->
  <div class="preloader">
    <div class="preloader-animation">
      <div class="preloader-spinner"></div>
    </div>
  </div>
  <!-- /Loading animation -->

  <!-- Scroll To Top Button -->
  <div class="lmpixels-scroll-to-top"><i class="lnr lnr-chevron-up"></i></div>
  <!-- /Scroll To Top Button -->

  <div class="page-scroll">
    <div id="page_container" class="page-container bg-move-effect" data-animation="transition-flip-in-right">

      <!-- Header -->
      <header id="site_header" class="header">
        <div class="header-content clearfix">

          <!-- Text Logo -->
          <div class="text-logo">
            <a href="index.html">
              <div class="logo-symbol">FM</div>
              <div class="logo-text">Fatima <span>Mamu</span></div>
            </a>
          </div>
          <!-- /Text Logo -->

          <!-- Navigation -->
          <div class="site-nav mobile-menu-hide">
            <ul class="leven-classic-menu site-main-menu">
              <li class="menu-item">
                <a href="index.html">About Me</a>
              </li>

              <li class="menu-item current-menu-item">
                <a href="projects.html">Projects</a>
              </li>

              <li class="menu-item">
                <a href="awards.html">Awards</a>
              </li>

              <li class="menu-item">
                <a href="media.html">Media</a>
              </li>
            </ul>
          </div>

          <!-- Mobile Menu Toggle -->
          <a class="menu-toggle mobile-visible">
            <i class="fa fa-bars"></i>
          </a>
          <!-- Mobile Menu Toggle -->
        </div>
      </header>
      <!-- /Header -->

      <div id="main" class="site-main">
        <div id="main-content" class="single-page-content">
          <div id="primary" class="content-area">

            <div class="page-title" style="text-align: center; padding: 40px 70px;">
              <h1>Selected Projects</h1>
              <div class="page-subtitle"></div>
            </div>

            <div id="content" class="page-content site-content single-post" role="main">

              <!-- Project 1 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Membership and Operations Platform</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Designed and built a full-stack membership and operations system for service-based businesses, covering
                          memberships, classes, bookings, payments, and staff workflows.
                          <br><br>
                          The backend was built around a normalized PostgreSQL schema with relational constraints to keep booking and
                          membership states consistent at scale.
                          <br><br>
                          Implemented REST API routes with input validation, structured error handling, and role-based authentication.
                          Added transactional booking logic and server-side checks to prevent double bookings under concurrent registrations.
                        </p>

                        <p>
                          <a href="#" target="_blank">View Repository</a>
                        </p>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 1 -->


              <!-- Project 2 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Emergency Maternal Transport Coordination System</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Built an end-to-end emergency coordination system connecting community health agents, drivers, and hospitals.
                          The platform supports symptom-based triage, driver selection, hospital capability matching, and real-time messaging.
                          <br><br>
                          Backend: Node.js/Express API with Firestore persistence and Firebase Cloud Messaging notifications.
                          Implemented the core workflow to map symptoms to emergency conditions, request fresh driver locations,
                          select candidate drivers, choose a hospital based on capability rules and travel-time heuristics, then persist and
                          broadcast the ride state.
                          <br><br>
                          Mobile: React Native app with role-based interfaces, background location tracking for drivers, and push notifications
                          for ride requests and status updates. Designed the system to handle low-connectivity environments with timeouts,
                          retry logic, and state reconciliation.
                        </p>

                        <p>
                          <a href="https://github.com/Timamamu/umma-na-backend" target="_blank">Backend Repo</a>
                          &nbsp;|&nbsp;
                          <a href="https://github.com/Timamamu/umma-na-mobile" target="_blank">Mobile Repo</a>
                          &nbsp;|&nbsp;
                          <a href="https://github.com/Timamamu/umma-na-frontend" target="_blank">Admin Frontend Repo</a>
                        </p>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 2 -->

              <!-- Project end -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Reinforcement Learning Simulation Environment</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Built a reinforcement learning training environment in Unity ML-Agents where an agent learns continuous
                          3D navigation and resource collection.
                          <br><br>
                          Defined the observation space, action space, and reward shaping logic, then configured and ran PPO training runs.
                          Exported and evaluated learned policies using a pre-trained model, with a workflow for re-training and iteration.
                        </p>

                        <p>
                          <a href="https://github.com/Timamamu/Reinforcement-Learning-in-Unity" target="_blank">View Repository</a>
                        </p>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 5 -->


              <!-- Project 3 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Computer Vision Soccer Analytics Pipeline</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Developed a computer vision pipeline that turns match footage into tactical analytics using detection,
                          multi-object tracking, camera motion compensation, and spatial transforms.
                          <br><br>
                          Fine-tuned a YOLOv8 model for soccer-specific classes and integrated ByteTrack for persistent IDs.
                          Implemented optical-flow-based camera motion compensation and a homography transform to map broadcast
                          coordinates into an approximate pitch reference for downstream distance and speed metrics.
                          <br><br>
                          Built possession inference by linking the tracked ball to the nearest player and rendered overlays for IDs, team
                          assignment, possession indicators, and per-player stats.
                        </p>

                        <p>
                          <a href="https://github.com/Timamamu/ugo-soccer-analytics" target="_blank">View Repository</a>
                        </p>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 3 -->


              <!-- Project 4 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Physical and Interactive Prototypes (Disney R&D)</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Built and integrated real-time prototypes combining Unity, sensor input, and physical systems for themed entertainment experiences.
                          <br><br>
                          Contributed to a robotics-driven show illusion prototype by helping with mechanical setup, calibration, testing, and timing alignment between motion and visuals. Built a multi-sensor interactive display that combined eye tracking, hand tracking, and projection into a single experience, then iterated through calibration passes under changing lighting and viewing conditions.<br><br>
                          Also developed Unity-based tools for synthetic dataset generation and an AR pre-visualization workflow to plan scene layout, spacing, and prop placement before physical build.
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 4 -->

              <!-- Project 5 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Virtual AI Photobooth</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          
                          Built a real-time generative photobooth system that applies AI-driven style transformations to live camera input for immersive, interactive experiences.
                          <br><br>
                          The pipeline captures webcam video, performs frame preprocessing, and routes frames through a generative model for stylized transformation. Implemented efficient frame buffering and inference scheduling to balance visual quality with low-latency output suitable for live display.
                          <br><br>
                          Integrated model inference with a responsive UI layer, handling user-triggered style selection, preview states, and final capture workflows. Structured the system to allow easy swapping of models and style presets, enabling rapid experimentation with different generative approaches.

                        </p>

                        <p>
                          <a href="https://github.com/Timamamu/virtual-photobooth" target="_blank">View Repository</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 5 -->

              <!-- Project 6 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Soma: EEG-to-Art Feedback Loop</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Created an interactive real-time art installation that converts live EEG neural signals into AI-generated visual art and explores human-machine feedback dynamics. 
                          <br><br>
                          Using a Muse EEG headset streamed via Lab Streaming Layer, the system captures electrical brain activity, transforms it into spectrogram representations, and feeds them into a pix2pix generative model trained to map neural patterns to visual domains. The result is a side-by-side live visualization of raw EEG spectrograms alongside AI-generated abstract art that reflects implicit patterns learned from collective brain responses.
                          <br><br>
                          Beyond the technical pipeline (spectrogram generation, STFT preprocessing, model inference, and real-time display), the project is framed as an experiential investigation of feedback loops between users and AI systems—raising questions about agency, implicit bias in learned representations, and how “neutral” systems can subtly influence subjective experience
                        </p>

                        <p>
                          <a href="https://github.com/Timamamu/Soma-EEG-to-Art-Feedback-Loop" target="_blank">View Repository</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 6 -->

              <!-- Project 7 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Painterly Rendering Toolkit</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Developed a real-time painterly rendering system that transforms 3D scenes into stylized, brush-stroke-inspired visuals using custom shader pipelines and image abstraction techniques.
                          <br><br>
                          Built a modular rendering framework that analyzes scene geometry, surface orientation, and lighting to drive stroke direction, texture blending, and color modulation. Implemented multi-pass rendering stages including edge detection, stroke orientation field computation, and adaptive brush density heuristics to approximate traditional media aesthetics.
                          <br><br>
                          Designed the system with runtime parameter controls for abstraction level, stroke density, and stylistic variation, enabling interactive experimentation while maintaining real-time performance. Structured the architecture to support extensibility for additional artistic styles and rendering effects.
                        </p>

                        <p>
                          <a href="https://github.com/Timamamu/painterly--rendering" target="_blank">View Repository</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 7 -->


              

              <!-- Project 8 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>AidAlly: AR-Guided Assembly for Humanitarian Aid Devices</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Built an offline-first AR mobile app that guides users step-by-step through assembling humanitarian aid devices in low-connectivity disaster environments.
                          <br><br>
                          Developed the full AR interaction system in Unity using AR Foundation (ARKit/ARCore), including object recognition for physical components, surface anchoring via plane detection + raycasting, and spatial instruction overlays designed to require no reading or translation.
                          <br><br>
                          Implemented a sequenced assembly flow using a state-machine approach: parts are detected and validated in 3D space, completion is logged to unlock subsequent steps, and users receive real-time visual feedback through ghosted previews, highlights, arrows, and alignment cues. Packaged all models, tracking data, and instruction logic locally to ensure reliable offline operation in low-resource conditions.
                        </p>

                        <p>
                          <a href="https://www.fatimamamu.com/projects/aid-ally" target="_blank">View Project</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 8 -->

              <!-- Project 9 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Single-Image Dehazing</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Built a single-image dehazing pipeline for image restoration using Dark Channel Prior and Color Attenuation Prior methods, with a focus on improving visual clarity while preserving edges and fine structure.
                          <br><br>
                          Compared classical dehazing approaches end-to-end and improved edge preservation by replacing soft matting with joint bilateral filtering and guided filtering for refined transmission estimation and cleaner depth boundaries.
                          <br><br>
                          Trained a linear depth model using brightness–saturation differences, integrating CLAHE and gamma correction as preprocessing steps to stabilize contrast and improve depth inference across varying haze densities.
                        </p>

                        <p>
                          <a href="https://www.fatimamamu.com/projects/dehazing" target="_blank">View Project</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 9 -->

              <!-- Project 10 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>DeepSDF: Neural Implicit 3D Shape Representation</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Implemented the DeepSDF architecture to learn continuous signed distance functions (SDFs) for neural implicit 3D shape representation.
                          <br><br>
                          Trained models on 3D shape datasets to encode object geometries into a compact latent space, enabling reconstruction of smooth, watertight surfaces through implicit function evaluation and marching cubes extraction.
                          <br><br>
                          Explored applications in shape interpolation and completion by traversing the learned latent space, demonstrating continuous transitions between object instances and robust reconstruction from partial geometry.
                        </p>

                        <p>
                          <a href="https://www.fatimamamu.com/projects/deepsdf" target="_blank">View Project</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 10 -->

              <!-- Project 11 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>The Butterfly Effect</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Created a responsive art installation exploring cause and effect through embodied interaction, visualizing how small human actions propagate into cascading system-wide responses.
                          <br><br>
                          Integrated physical sensors with Arduino for real-time input capture and processed live data streams in Processing to drive projection-mapped visuals. Designed the interaction model so viewer proximity and movement dynamically altered generative patterns, creating an evolving feedback loop between participant and system.
                          <br><br>
                          Structured the installation as a hybrid physical-digital system, coordinating hardware input, signal processing, and projection output to maintain responsiveness while preserving conceptual coherence around amplification and systemic interdependence.
                        </p>

                        <p>
                          <a href="https://cardioid-octopus-bwps.squarespace.com/projects-1/the-butterfly-effect-jnz63" target="_blank">View Project</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 11 -->

              <!-- Project 12 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Haptic Feedback Device</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Developed a custom haptic feedback device that translates digital interaction signals into tangible tactile responses.
                          <br><br>
                          Designed and prototyped the hardware using microcontrollers and actuator arrays to generate localized vibration patterns corresponding to system events. Implemented sensor integration for real-time feedback loops and fine-tuned actuation profiles to deliver nuanced haptic sensations.
                          <br><br>
                          Built the supporting software interface to interpret input events and map them to haptic outputs, creating an intuitive physical layer of interaction that enhances user perception of digital states through touch.
                        </p>

                        <p>
                          <a href="https://cardioid-octopus-bwps.squarespace.com/projects-1/haptic-feedback-device-nmlys" target="_blank">View Project</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 12 -->

              <!-- Project 13 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Buster: 3D Platformer Game</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Created a 3D platformer game featuring physics-driven movement, interactive environments, and responsive character mechanics.
                          <br><br>
                          Built core gameplay systems including jumping, collision response, and enemy interactions using a game engine framework, and structured level flow with checkpoints and escalating challenge.
                          <br><br>
                          Implemented camera control logic and animation blending to enhance player experience, combining intuitive controls with dynamic feedback loops for smooth in-game navigation and engagement.
                        </p>

                        <p>
                          <a href="https://cardioid-octopus-bwps.squarespace.com/projects-1/buster-3d-game-7pxej" target="_blank">View Project</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 13 -->

              <!-- Project 14 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Swipe Mosaic</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Built an interactive digital mosaic experience where users swipe to reveal and transform image tiles in real time.
                          <br><br>
                          Designed and implemented responsive touch interactions to track swipe gestures and progressively update the mosaic layout based on user input. Developed dynamic tile animation and blending logic to create fluid visual transitions between states.
                          <br><br>
                          Optimized rendering performance to ensure smooth interactions across devices, and structured the project to support extensibility for new tile effects and interaction patterns.
                        </p>

                        <p>
                          <a href="https://cardioid-octopus-bwps.squarespace.com/projects-1/swipe-mosaic-6lwy2" target="_blank">View Project</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 14 -->

              <!-- Project 15 -->
              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="p-10"></div>
                  <div class="block-title">
                    <h2>Seeds of Time</h2>
                  </div>
                </div>
              </div>

              <div class="row">
                <div class="col-xs-12 col-sm-12">
                  <div class="info-list-w-icon">
                    <div class="info-block-w-icon">
                      <div class="ci-text">
                        <p>
                          Built a responsive computational design prototype combining parametric modeling with physical computing to explore how architectural form can adapt to real-time environmental data.
                          <br><br>
                          Used Grasshopper and Rhino to generate parametric geometries and mapped Arduino sensor inputs into live parameter updates, allowing the digital model to change continuously based on sensed conditions.
                          <br><br>
                          Connected digital fabrication workflows with sensor-driven interactivity, demonstrating a feedback loop between physical signals and computational form generation for adaptive design exploration.
                        </p>

                        <p>
                          <a href="https://cardioid-octopus-bwps.squarespace.com/projects-1/seeds-of-time-zr5zm" target="_blank">View Project</a>
                        </p>

                        
                      </div>
                    </div>
                  </div>
                </div>
              </div>
              <!-- /Project 15 -->

            </div>
          </div>
        </div>
      </div>

      <!-- Footer -->
      <footer class="site-footer clearfix">
        <div class="footer-social">
          <ul class="footer-social-links">
            <li><a href="https://github.com/Timamamu" target="_blank">GitHub</a></li>
            <li><a href="#" target="_blank">LinkedIn</a></li>
            <li><a href="#" target="_blank">Email</a></li>
          </ul>
        </div>

        <div class="footer-copyrights">
          <p>© Fatima Mamu</p>
        </div>
      </footer>
      <!-- /Footer -->

    </div>
  </div>

  <script src="js/jquery-2.1.3.min.js"></script>
  <script src="js/imagesloaded.pkgd.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/jquery.shuffle.min.js"></script>
  <script src="js/masonry.pkgd.min.js"></script>
  <script src="js/owl.carousel.min.js"></script>
  <script src="js/jquery.magnific-popup.min.js"></script>
  <script src="js/validator.js"></script>
  <script src="js/main.js"></script>
</body>
</html>